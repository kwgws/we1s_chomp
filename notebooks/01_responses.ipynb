{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # STEP 1: SCRAPE RESPONSES\n",
    "\n",
    "<h4>This notebook will collect responses containing article metadata from RESTful web-facing search APIs.</h4>\n",
    " \n",
    "It supports the Wordpress API (reference here: https://developer.wordpress.org/rest-api/) and the Google Custom Search Engine API (reference here: https://developers.google.com/custom-search/v1/) out of the box, though other APIs can be added. For more information and further instructions, consult the Chomp documentation at https://github.com/kwgws/we1s_chomp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## INFO\n",
    "\n",
    "__authors__    = 'Catherine Gilleran'  \n",
    "__copyright__  = 'copyright 2019, The WE1S Project'  \n",
    "__license__    = 'MIT'  \n",
    "__version__    = '0.1.0'  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import getenv\n",
    "from pathlib import Path\n",
    "\n",
    "from we1s_chomp import clean, db, google, wordpress\n",
    "from we1s_chomp.model import Response\n",
    "from we1s_chomp.web import Browser\n",
    "\n",
    "\n",
    "project_dir = Path.home() / \"write\" / \"dev\" / \"we1s_chomp\"\n",
    "url_stopwords_file = project_dir / \"notebooks\" / \"url_stopwords.txt\"\n",
    "\n",
    "grid_url = getenv(\"CHOMP_SELENIUM_GRID_URL\")\n",
    "google_cx = getenv(\"CHOMP_GOOGLE_CX\")\n",
    "google_key = getenv(\"CHOMP_GOOGLE_KEY\")\n",
    "\n",
    "wp_endpoints = [\"pages\", \"posts\"]\n",
    "url_stops = set()\n",
    "\n",
    "# Get stopwords.\n",
    "url_stopwords = set()\n",
    "with open(url_stopwords_file, encoding=\"utf-8\") as txtfile:\n",
    "    for line in txtfile.readlines():\n",
    "        stopword = line.strip()\n",
    "        if stopword != \"\":\n",
    "            url_stopwords.add(stopword)\n",
    "            print(f'Added URL stopword: \"{stopword}\".')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DATA DIRECTORIES\n",
    "\n",
    " Chomp will import and export JSON files to these directories, using them not\n",
    " only to set up and store the results of a collection run and but also to keep\n",
    " track of metadata, duplicate URLs, page numbers, etc. as it goes.\n",
    "\n",
    " <p style=\"color:red;\">Because collection is a time- and resource-intensive\n",
    " task, it is preferable to keep these metadata files in a single location and\n",
    " allow Chomp to manage them internally rather than modifying or deleting them\n",
    " between each job.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dir = project_dir / \"data\" / \"json\" / \"queries\"\n",
    "source_dir = project_dir / \"data\" / \"json\" / \"sources\"\n",
    "response_dir = project_dir / \"data\" / \"json\" / \"responses\"\n",
    "\n",
    "# Make response directory if it does not already exist.\n",
    "if not response_dir.exists():\n",
    "    response_dir.mkdir(parents=True)\n",
    "\n",
    "print(f\"Loading sources from {source_dir}.\")\n",
    "print(f\"Loading queries from {query_dir}.\")\n",
    "print(f\"Saving responses to {response_dir}.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## BROWSE: Search queries for keywords\n",
    "\n",
    "Choose `search_text` to filter available query files. If you are searching for a specific word or phrase, enter it WITHIN the single quotes below. Note that you will be searching the filenames of the JSON files stored on in the `query_dir` path (usually `data/json/queries`). If you want to simply list all of the available queries, change the value of the `search_text` variable below to `None` WITHOUT single quotes (so the line should read `search_text = None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_text = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell and review the results. The default is to search through the `data/json/queries` directory. If your data is in a different location on harbor, change the `query_dir` variable above to the directory you want to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"query_list = [\")\n",
    "for filename in query_dir.glob(\"*.json\"):\n",
    "    if search_text is not None and search_text not in filename:\n",
    "        continue\n",
    "    with open(filename, encoding=\"utf-8\") as jsonfile:\n",
    "        name = json.load(jsonfile).get(\"name\", \"\")\n",
    "    print('    \"' + name + '\",')\n",
    "print(\"]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIST: Define which queries will be scraped\n",
    "\n",
    "Copy the entire cell output above and replace the `query_list` array in the following cell. Each name should be surrounded by quotes, and after each name there should be a comma (for the last filename in the list it doesn't matter if you include the comma or not).\n",
    "\n",
    "Don't forget to run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\n",
    "    \"we1s_humanities_01-01-2014_12-31-2019\",\n",
    "    \"libcom-org_humanities_01-01-2000_12-31-2019\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## IMPORT & TEST QUERIES\n",
    "\n",
    " Let's take a second here to make sure our queries are in good shape--that the\n",
    " dates are all correct and that they all connect to a proper source. That way\n",
    " there won't be any surprises later.\n",
    "\n",
    " Run this cell and check for any errors in the output. Make sure that the\n",
    " number of queries imported is equal to the number of queries you intended\n",
    " to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "for query_name in query_list:\n",
    "    query = db.load_query(query_name, query_dir)\n",
    "    if not db.load_source(query.source, source_dir):\n",
    "        print(f'WRN: \"{query.source}\" not found, skipping \"{query.name}\"')\n",
    "        continue\n",
    "    queries.append(query)\n",
    "    print(f'Imported \"{query.name}\".')\n",
    "print(f\"{len(queries)} queries imported out of {len(query_list)} total.\")\n",
    "if len(queries) == len(query_list):\n",
    "    print(\"Everything looks good so far!\\n\\n\")\n",
    "else:\n",
    "    print(\"Hmm, does that seem right to you? Double-check!\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## LOAD URL STOPS (Optional)\n",
    "\n",
    " Load previously collected URLs. Skipping this step will force all responses to be re-collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    for response_name in query.responses:\n",
    "        response = db.load_response(response_name, response_dir)\n",
    "        url_stops.add(response.url)\n",
    "print(f\"Added {len(url_stops)} URLs to URL stop list.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # GET RESPONSES\n",
    "\n",
    " Use the queries to start scraping responses.\n",
    " \n",
    " <h3 style=\"color:red;font-weight:bold\">Pay close attention to errors here--many things can go wrong when dealing with the web!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%time\n",
    "total = 0\n",
    "\n",
    "# Start browser connection.\n",
    "browser = Browser(grid_url)\n",
    "\n",
    "for query in queries:\n",
    "\n",
    "    # Load associated source.\n",
    "    source = db.load_source(query.source, source_dir)\n",
    "    base_url = source.webpage\n",
    "\n",
    "    # Select scraping API.\n",
    "    api = \"wordpress\" if wordpress.is_api_available(base_url, browser) else \"google\"\n",
    "    responses = None\n",
    "\n",
    "    # Wordpress API ##########################################################\n",
    "    if api == \"wordpress\":\n",
    "        print(f'\\nCollecting \"{query.name}\" via Wordpress API...')\n",
    "        responses = wordpress.get_responses(\n",
    "            query_str=query.query_str,\n",
    "            base_url=base_url,\n",
    "            endpoints=wp_endpoints,\n",
    "            url_stops=url_stops,\n",
    "            url_stopwords=url_stopwords,\n",
    "            browser=browser,\n",
    "        )\n",
    "\n",
    "    # Google API #############################################################\n",
    "    else:\n",
    "        print(f'\\nCollecting \"{query.name}\" via Google API...')\n",
    "        responses = google.get_responses(\n",
    "            query_str=query.query_str,\n",
    "            base_url=base_url,\n",
    "            google_cx=google_cx,\n",
    "            google_key=google_key,\n",
    "            url_stops=url_stops,\n",
    "            url_stopwords=url_stopwords,\n",
    "            browser=browser,\n",
    "        )\n",
    "\n",
    "    if not responses:\n",
    "        print(\"ERR: No results or connection error!\")\n",
    "        continue\n",
    "\n",
    "    # Loop over each page we get back and save the raw response JSON.\n",
    "    count = 0\n",
    "    for res in responses:\n",
    "        url, content = res\n",
    "        if not res or not content or content == \"\":\n",
    "            print(\"WRN: No response, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Add Chomp metadata.\n",
    "        response = Response(\n",
    "            name=\"_\".join(\n",
    "                [\n",
    "                    \"chomp-response\",\n",
    "                    source.name,\n",
    "                    query.query_str,\n",
    "                    clean.date_to_str(query.start_date),\n",
    "                    clean.date_to_str(query.end_date),\n",
    "                    str(count),\n",
    "                ]\n",
    "            ),\n",
    "            url=url,\n",
    "            content=content,\n",
    "            chompApi=api,\n",
    "            source=source.name,\n",
    "            query=query.name,\n",
    "        )\n",
    "\n",
    "        # Save result.\n",
    "        count += 1\n",
    "        total += 1\n",
    "        db.save_response(response, response_dir)\n",
    "\n",
    "        # Update query.\n",
    "        query.responses.add(response.name)\n",
    "        db.save_query(query, query_dir)\n",
    "\n",
    "        # Update source.\n",
    "        source.responses.add(response.name)\n",
    "        db.save_source(source, source_dir)\n",
    "\n",
    "        print(f\"- {response.url}\")\n",
    "    print(f\"Done! Got {count} responses from this query.\\n\\n\")\n",
    "print(f\"\\nAll queries complete! Got a total of {total} responses.\\n\\n\")\n",
    "print(\"\\n\\n----------Time----------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## NEXT NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: next notebook code\n",
    "# Go to 02_articles.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
